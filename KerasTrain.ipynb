{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KerasTrain.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"iBx8gFymEQz0","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","from typing import Optional\n","\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O7DDhj5BEXpD","colab_type":"code","colab":{}},"cell_type":"code","source":["# Authenticate to GCS.\n","from google.colab import auth\n","auth.authenticate_user()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"00roeDtOEr5S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"5768d2b7-6e7f-4a2e-8ab2-781ce8cd7df9","executionInfo":{"status":"ok","timestamp":1548977406575,"user_tz":-660,"elapsed":4486,"user":{"displayName":"Damien Pontifex","photoUrl":"https://lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s64/photo.jpg","userId":"16810753429267026652"}}},"cell_type":"code","source":["tf.gfile.ListDirectory('gs://pontiml/inria/records')"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['train-0.tfrecord',\n"," 'train-1.tfrecord',\n"," 'train-2.tfrecord',\n"," 'train-3.tfrecord',\n"," 'train-4.tfrecord',\n"," 'train-5.tfrecord',\n"," 'train-6.tfrecord',\n"," 'train-7.tfrecord',\n"," 'train-8.tfrecord',\n"," 'train-9.tfrecord',\n"," 'validation-0.tfrecord']"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"yimt4TPIEQz8","colab_type":"text"},"cell_type":"markdown","source":["## Data"]},{"metadata":{"id":"7aWOHfsGEQz-","colab_type":"code","colab":{}},"cell_type":"code","source":["def _map_batch(record_batch):\n","    img_batch = tf.decode_raw(record_batch['image/bytes'], tf.uint8)\n","    img_batch = tf.reshape(img_batch, (-1, 1000, 1000, 3))\n","    img_batch = tf.image.resize_images(img_batch, (512, 512))\n","\n","    img_batch = tf.image.convert_image_dtype(img_batch, dtype=tf.float32)\n","\n","    label_batch = tf.decode_raw(record_batch['image/label'], tf.float32)\n","    #         label_batch = tf.expand_dims(label_batch, axis=-1)\n","    label_batch = tf.reshape(label_batch, (-1, 1000, 1000))\n","    label_batch = tf.expand_dims(label_batch, axis=-1)\n","\n","    label_batch = tf.image.resize_images(label_batch, (512, 512))\n","\n","    # Need to make sure same transformation is done to image and label...maybe use seed?\n","    # Or something like https://stackoverflow.com/a/38403715/1602729\n","#     if training:\n","#         # Do some random image augmentation - need to make sure it's random but applied to both image and label\n","#         image_raw = tf.image.random_flip_left_right(image_raw)\n","#         label_raw = tf.image.random_flip_left_right(label_raw)\n","\n","    return { 'image': img_batch }, label_batch\n","\n","def make_dataset(file_pattern, num_epochs=None, batch_size=32, shuffle=True):\n","\n","    features = {\n","        'image/height': tf.FixedLenFeature([], tf.int64),\n","        'image/width': tf.FixedLenFeature([], tf.int64),\n","        'image/label': tf.FixedLenFeature([], tf.string),\n","        'image/bytes': tf.FixedLenFeature([], tf.string)\n","    }\n","\n","    dataset = tf.data.experimental.make_batched_features_dataset(\n","        file_pattern, batch_size, features,\n","        num_epochs=num_epochs, shuffle=shuffle,\n","        shuffle_buffer_size=4*batch_size, sloppy_ordering=True,\n","        reader_num_threads=os.cpu_count(), parser_num_threads=os.cpu_count(),\n","        prefetch_buffer_size=4)\n","\n","    dataset = dataset.map(_map_batch)\n","\n","    return dataset"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dBN66hHqEQ0C","colab_type":"text"},"cell_type":"markdown","source":["## Model"]},{"metadata":{"id":"7Xcc8YxGG2HV","colab_type":"text"},"cell_type":"markdown","source":["<img alt=\"unet model architecture\" src=\"http://deeplearning.net/tutorial/_images/unet.jpg\" width=500 />\n"]},{"metadata":{"id":"OnN1EBNKEQ0G","colab_type":"code","colab":{}},"cell_type":"code","source":["l = tf.keras.layers\n","\n","def _conv_block(inputs: tf.Tensor, filters: int, name: str, repeat: int=2) -> tf.Tensor:\n","    \"\"\"Repeated 3x3 2d convolutions with ReLU\"\"\"\n","    layer = inputs\n","    for idx, _ in enumerate(range(repeat)):\n","        layer = l.Conv2D(filters, kernel_size=3, activation=tf.nn.relu, \n","                         padding='same', name=f'{name}_{idx}')(layer)\n","    return layer\n","\n","\n","def _up_conv(inputs: tf.Tensor) -> tf.Tensor:\n","    \"\"\"Deconvolution\"\"\"\n","    input_shape = inputs.get_shape().as_list()\n","    return l.Conv2DTranspose(filters=input_shape[-1], kernel_size=2, strides=2, \n","                             padding='same', activation=tf.nn.relu)(inputs)\n","\n","\n","def unet_model(batch_size: Optional[int]=None) -> tf.keras.Model:\n","    \"\"\"Function to build the unet model architecture\"\"\"\n","    \n","    image_input = l.Input(shape=(512, 512, 3), batch_size=batch_size,\n","                          name='image', dtype=tf.float32)\n","\n","    # Provide sample of original image to tensorboard\n","    tf.summary.image('inputs', image_input)\n","    \n","#     if labels is not None:\n","#         # Sample of our truth label for tensorboard\n","#         tf.summary.image('labels', labels)\n","\n","    # Use the image as the input or our current head of the model\n","    net = image_input\n","    \n","    # Used to store layers that are copied to the up-path of the unet model\n","    copy_layers = []\n","    # Define the number of filters in each stage of the up and down path\n","    filter_counts = [64, 128, 256, 512]\n","\n","    # Contractive path\n","    for idx, num_filters in enumerate(filter_counts):\n","        net = _conv_block(net, num_filters, name=f'contracting{idx}')\n","        copy_layers.append(net)\n","        net = l.MaxPool2D(pool_size=2, strides=2, padding='same')(net)\n","    \n","    # Apply final conv that doesn't have output copied and no maxpool\n","    net = _conv_block(net, 2 * filter_counts[-1], name='conexp')\n","\n","    # Expansive path\n","    for idx, num_filters in enumerate(reversed(filter_counts)):\n","        net = _up_conv(net)\n","        copy_layer = copy_layers.pop()\n","        net = l.concatenate([net, copy_layer], axis=3)\n","        net = _conv_block(net, num_filters, name=f'expansive{idx}')\n","\n","    # Conv 1x1 to get output segmentation map\n","    logits = l.Conv2D(filters=1, kernel_size=1, activation=tf.nn.sigmoid, \n","                      padding='same')(net)\n","    \n","    tf.summary.image('predictions', logits)\n","    \n","    return tf.keras.Model(inputs=image_input, outputs=logits)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uehnX6XsEQ0I","colab_type":"text"},"cell_type":"markdown","source":["## Train"]},{"metadata":{"id":"hAFz2E4XEQ0J","colab_type":"code","colab":{}},"cell_type":"code","source":["data_dir = os.environ.get('DATA_DIR', 'gs://pontiml/inria/records')\n","model_dir = os.environ.get('MODEL_DIR', 'gs://pontiml/inria/model/run6')\n","max_steps = int(os.environ.get('MAX_STEPS', 10000))\n","batch_size = int(os.environ.get('BATCH_SIZE', 2))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s9tv-adgEQ0L","colab_type":"code","colab":{}},"cell_type":"code","source":["tf.gfile.MakeDirs(model_dir)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GGTrJegQEQ0N","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size_multiplier = 1\n","\n","if 'COLAB_TPU_ADDR' in os.environ:\n","    distribute = tf.contrib.distribute.TPUStrategy()\n","    \n","    # Cloud TPU contains 8 TPU cores\n","    batch_size_multiplier = 8\n","else:\n","    distribute = tf.contrib.distribute.MirroredStrategy()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3qWfET9CEQ0O","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size *= batch_size_multiplier"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Kj_LuAq8EQ0Q","colab_type":"code","colab":{}},"cell_type":"code","source":["model = unet_model(batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eAQmsBe_EQ0R","colab_type":"code","colab":{}},"cell_type":"code","source":["model.compile(\n","    optimizer=tf.train.AdamOptimizer(learning_rate=1e-2),\n","    loss=tf.losses.sigmoid_cross_entropy,\n","    metrics=[tf.keras.metrics.binary_accuracy],\n","#     distribute=distribute\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sYRAPf7IEQ0S","colab_type":"code","colab":{}},"cell_type":"code","source":["train_ds = make_dataset(os.path.join(data_dir, 'train-*.tfrecord'), batch_size=batch_size, shuffle=True)\n","val_ds = make_dataset(os.path.join(data_dir, 'validation-0.tfrecord'), batch_size=batch_size, shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7FAp66iQEQ0U","colab_type":"code","colab":{}},"cell_type":"code","source":["tensorboard = tf.keras.callbacks.TensorBoard(log_dir=model_dir)\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(model_dir, 'model.ckpt.hdf5'))\n","\n","callbacks = [tensorboard, model_checkpoint]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"i1mwIGzgGTFX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2445},"outputId":"58169316-d6f1-4a32-afb0-d902e682cb9a","executionInfo":{"status":"error","timestamp":1548977321560,"user_tz":-660,"elapsed":1551,"user":{"displayName":"Damien Pontifex","photoUrl":"https://lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s64/photo.jpg","userId":"16810753429267026652"}}},"cell_type":"code","source":["model.fit(\n","    train_ds, validation_data=val_ds, batch_size=batch_size, # steps_per_epoch=100, \n","    validation_steps=100//batch_size, epochs=10, \n","    callbacks=callbacks)"],"execution_count":20,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Expected len(dense_defaults) == len(dense_keys) but got: 4 vs. 0\n\t [[{{node ParseExampleDataset}} = ParseExampleDataset[Tdense=[DT_STRING, DT_INT64, DT_STRING, DT_INT64], _class=[\"loc:@MakeIterator\"], dense_keys=[\"image/bytes\", \"image/height\", \"image/label\", \"image/width\"], dense_shapes=[[], [], [], []], output_shapes=[[2], [2], [2], [2]], output_types=[DT_STRING, DT_INT64, DT_STRING, DT_INT64], sparse_keys=[], sparse_types=[], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](BatchDatasetV2, ParseExampleDataset/num_parallel_calls, Const_1, Const_2, Const_1, Const_2)]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-13cb23cf7c0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# steps_per_epoch=100,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     callbacks=callbacks)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    945\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_iterator_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m           \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# Validates `steps` argument based on x's type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Expected len(dense_defaults) == len(dense_keys) but got: 4 vs. 0\n\t [[node ParseExampleDataset (defined at <ipython-input-14-d28f46b3b80d>:1)  = ParseExampleDataset[Tdense=[DT_STRING, DT_INT64, DT_STRING, DT_INT64], _class=[\"loc:@MakeIterator\"], dense_keys=[\"image/bytes\", \"image/height\", \"image/label\", \"image/width\"], dense_shapes=[[], [], [], []], output_shapes=[[2], [2], [2], [2]], output_types=[DT_STRING, DT_INT64, DT_STRING, DT_INT64], sparse_keys=[], sparse_types=[], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](BatchDatasetV2, ParseExampleDataset/num_parallel_calls, Const_1, Const_2, Const_1, Const_2)]]\n\nCaused by op 'ParseExampleDataset', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-d28f46b3b80d>\", line 1, in <module>\n    model.fit(train_ds, batch_size=batch_size, validation_data=val_ds, steps_per_epoch=100, validation_steps=50, epochs=10, callbacks=callbacks)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1536, in fit\n    validation_split=validation_split)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 944, in _standardize_user_data\n    iterator = x.make_initializable_iterator()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 146, in make_initializable_iterator\n    dataset._as_variant_tensor(),  # pylint: disable=protected-access\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 2618, in _as_variant_tensor\n    input_t = self._input_dataset._as_variant_tensor()  # pylint: disable=protected-access\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 2812, in _as_variant_tensor\n    self._input_dataset._as_variant_tensor(),  # pylint: disable=protected-access\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/experimental/ops/parsing_ops.py\", line 91, in _as_variant_tensor\n    **dataset_ops.flat_structure(self))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 4570, in parse_example_dataset\n    output_types=output_types, output_shapes=output_shapes, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Expected len(dense_defaults) == len(dense_keys) but got: 4 vs. 0\n\t [[node ParseExampleDataset (defined at <ipython-input-14-d28f46b3b80d>:1)  = ParseExampleDataset[Tdense=[DT_STRING, DT_INT64, DT_STRING, DT_INT64], _class=[\"loc:@MakeIterator\"], dense_keys=[\"image/bytes\", \"image/height\", \"image/label\", \"image/width\"], dense_shapes=[[], [], [], []], output_shapes=[[2], [2], [2], [2]], output_types=[DT_STRING, DT_INT64, DT_STRING, DT_INT64], sparse_keys=[], sparse_types=[], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](BatchDatasetV2, ParseExampleDataset/num_parallel_calls, Const_1, Const_2, Const_1, Const_2)]]\n"]}]},{"metadata":{"id":"JKekfeUgHXDe","colab_type":"code","colab":{}},"cell_type":"code","source":["model.save_weights(os.path.join(model_dir, 'unet_model.h5'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SGYMgu7CEQ0V","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","\n","if 'COLAB_TPU_ADDR' in os.environ:\n","    TPU_WORKER = f'grpc://{os.environ[\"COLAB_TPU_ADDR\"]}'\n","    \n","    tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n","        model, strategy=tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n","    \n","    \n","else:\n","    model.fit()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oxlQLI0wEQ0W","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"O4fEOCIpEQ0Y","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}